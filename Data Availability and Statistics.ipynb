{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e94d3a",
   "metadata": {},
   "source": [
    "# data availability and states\n",
    "\n",
    "date format in this notebook is yyyy-mm-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16954e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6f2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluate import evaluate, r4\n",
    "from utils.openai import OpenAIEmbedding\n",
    "from utils.utils import human_format_number, human_format_number2\n",
    "from utils.companies import company100_name, company100_name_shorten, company100_ticker\n",
    "\n",
    "OAE = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51bda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcessor.historic import get_target, get_momentums, historic_moving_average_6m\n",
    "from DataProcessor.historic import historic_vol_moving_average_6m, historic_6m, historic_moving_std_6m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ef3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcessor.news import historic_news_wsj, historic_news_nyt, historic_news_cmin, historic_news_alphav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894d6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcessor.financials import financials_nq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d9eda",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f63e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../dataset/'\n",
    "historic_data_path = '../dataset/Historical Price/'\n",
    "financials_data_path = '../dataset/Financial Quarterly Reports/'\n",
    "news_data_path = '../dataset/News Articles/'\n",
    "news_wsj_path = '../dataset/News Articles/WSJ-Header/'\n",
    "news_nyt_path = '../dataset/News Articles/NYT/110/'\n",
    "news_alphav_path = '../dataset/News Articles/Alpha-V/without text 104/'\n",
    "news_CMINUS_path = '../dataset/News Articles/CMIN-US/'\n",
    "dotcsv = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7f21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_list(path):\n",
    "    listt = os.listdir(path)\n",
    "    if '.DS_Store' in listt:\n",
    "        listt.remove('.DS_Store')\n",
    "    if '.ipynb_checkpoints' in listt:\n",
    "        listt.remove('.ipynb_checkpoints')\n",
    "    return listt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeff9b9",
   "metadata": {},
   "source": [
    "### Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69adbae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for: BBL BHP\n",
      "no data for: PTR PetroChina\n",
      "no data for: RDS-B Royal Dutch\n"
     ]
    }
   ],
   "source": [
    "for ticker, name in zip(company100_ticker,company100_name_shorten):\n",
    "    try:\n",
    "        a = get_target(ticker, '2020-01-01', binn = False)\n",
    "        a = get_momentums(ticker, '2020-01-01', binn = False)\n",
    "        a = historic_moving_average_6m(ticker, '2020-01-01')\n",
    "        a = historic_moving_std_6m(ticker, '2020-01-01')\n",
    "        a = historic_vol_moving_average_6m(ticker, '2020-01-01')\n",
    "        a = historic_6m(ticker, '2020-01-01')\n",
    "    except:\n",
    "        print('no data for:', ticker, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e642ca7",
   "metadata": {},
   "source": [
    "### News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabe53f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBL 2024-06-30 error occured reading alphav\n",
      "DD 2024-06-30 error occured reading nyt\n",
      "SNPMF 2024-06-30 error occured reading nyt\n",
      "PTR 2024-06-30 error occured reading alphav\n",
      "RDS-B 2024-06-30 error occured reading alphav\n",
      "JPM 2024-06-30 error occured reading alphav\n",
      "total of 75541 articles.\n"
     ]
    }
   ],
   "source": [
    "all_news_count = []\n",
    "for ticker, name in zip(company100_ticker,company100_name_shorten):\n",
    "    try:\n",
    "        a = 100 #historic_news_wsj(ticker, '2024-06-31', '120m')\n",
    "    except:\n",
    "        print('no wsj data for:', ticker, name)\n",
    "    try:\n",
    "        b = len(historic_news_nyt(ticker, '2024-06-30', '120m'))\n",
    "    except:\n",
    "        print('no nyt data for:', ticker, name)\n",
    "    try:\n",
    "        c = len(historic_news_cmin(ticker, '2024-06-30', '120m'))\n",
    "    except:\n",
    "        print('no cmin data for:', ticker, name)\n",
    "    try:\n",
    "        d = len(historic_news_alphav(ticker, '2024-06-30', '120m'))\n",
    "    except:\n",
    "        print('no alphav data for:', ticker, name)\n",
    "    all_news_count.append(d)\n",
    "print('total of', sum(all_news_count), 'articles.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704be0c",
   "metadata": {},
   "source": [
    "### Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "439ef810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for: FB facebook\n",
      "no data for: BBL BHP\n",
      "no data for: SNPMF China Petroleum\n",
      "no data for: SPG Simon Property\n",
      "no data for: C Citigroup\n",
      "no data for: PTR PetroChina\n",
      "no data for: RDS-B Royal Dutch\n",
      "no data for: WFC Wells Fargo\n"
     ]
    }
   ],
   "source": [
    "for ticker, name in zip(company100_ticker,company100_name_shorten):\n",
    "    try:\n",
    "        a = financials_nq(ticker, '2024-12-01', 40)\n",
    "    except:\n",
    "        print('no data for:', ticker, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6440a6",
   "metadata": {},
   "source": [
    "### numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c8eb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50.000', '5.0K', '-2.5M', '0.8B', '-1.2T']\n"
     ]
    }
   ],
   "source": [
    "numbers = [50, 5000, -2500000, 750000000, -1234567890123]\n",
    "formatted_numbers = [human_format_number(num) for num in numbers]\n",
    "print(formatted_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e65127",
   "metadata": {},
   "source": [
    "### Create Movement Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e2b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_historic(ticker, qdate, include_volume = 0.7):\n",
    "    try:\n",
    "        ma = \", \".join(r4(historic_moving_average_6m(ticker, qdate)))\n",
    "        nancount = ma.count('nan')\n",
    "        if nancount > 1:\n",
    "            return -1\n",
    "        moving_average_temp = \"\"\"average market price for last 6 monts from old to new: $ma$\"\"\"\n",
    "        res = moving_average_temp.replace('$ma$', ma)\n",
    "        if np.random.rand() >= include_volume:\n",
    "            formatted_numbers = [human_format_number2(num) for num in historic_vol_moving_average_6m(ticker, qdate)]\n",
    "            va = \", \".join(formatted_numbers)\n",
    "            moving_volume_temp = \"\"\"average volume of exchange for last 6 monts from old to new: $va$\"\"\"\n",
    "            moving_volume_temp = moving_volume_temp.replace('$va$', va)\n",
    "            res = res + '\\n' + moving_volume_temp\n",
    "    except:\n",
    "        print(ticker, qdate, 'grabber: no historic data for: ', ticker)\n",
    "        return -1\n",
    "    return str('historic price data:\\n'+res)\n",
    "\n",
    "def process_financials(ticker, qdate, include = 2):\n",
    "    try: \n",
    "        res = 'financial data for last four quarters from old to new:\\n'\n",
    "        fins = financials_nq(ticker, qdate, 4)\n",
    "        keys = list(fins.keys())[1:]\n",
    "        if len(keys) <= 10:\n",
    "            return -1\n",
    "        include = min(include, len(keys)-1)\n",
    "        sampled_keys = random.sample(keys, include)\n",
    "        sampled_dict = {key: fins[key] for key in sampled_keys}\n",
    "        a = [kl + ': ' + \", \"\n",
    "             .join([str(human_format_number2(num)) for num in sampled_dict[kl]]) for kl in sampled_dict]\n",
    "        for i in a:\n",
    "            if len(i) < 30:\n",
    "                return -1\n",
    "            if i.count('nan') > 2:\n",
    "                return -1\n",
    "    except:\n",
    "        print(ticker, qdate, 'grabber: no financials data for: ', ticker)\n",
    "        return -1\n",
    "    return res + '\\n'.join(a)\n",
    "\n",
    "def process_news(ticker, qdate, include = 3):\n",
    "    \n",
    "    news = historic_news_nyt(ticker, qdate, '1m')\n",
    "    news += historic_news_wsj(ticker, qdate, '1m')\n",
    "    news += historic_news_alphav(ticker, qdate, '1m')\n",
    "    news += historic_news_cmin(ticker, qdate, '1m')\n",
    "\n",
    "    if len(news) < 10:\n",
    "        news = historic_news_nyt(ticker, qdate, '3m')\n",
    "        news += historic_news_wsj(ticker, qdate, '3m')\n",
    "        news += historic_news_alphav(ticker, qdate, '3m')\n",
    "        news += historic_news_cmin(ticker, qdate, '3m')\n",
    "    \n",
    "    if len(news)>10:\n",
    "        news1 = []\n",
    "        for new in news:\n",
    "            if len(str(new['abstract']))>20:\n",
    "                news1.append(new)\n",
    "        news = news1\n",
    "        \n",
    "    news1 = []\n",
    "    for new in news:\n",
    "        if len(str(new['headline']))>10:\n",
    "            news1.append(new)\n",
    "    news = news1\n",
    "    \n",
    "    news1 = []\n",
    "    for new in news:\n",
    "        a = new['headline']+ ' ' + str(new['abstract'])\n",
    "        a.split()\n",
    "        if len(a)<500:\n",
    "            news1.append(new)\n",
    "    news = news1\n",
    "    \n",
    "    if len(news) < 3:\n",
    "        return -1, -1\n",
    "    \n",
    "    enews = [OAE.get_embedding(i['headline']+ ' ' + str(i['abstract'])) for i in news]\n",
    "    query = \"investing in $$ company. influence on stock price. news that have information on the value of stock.\"\n",
    "    query = query.replace('$$', company100_name[company100_ticker.index(ticker)])\n",
    "    equery = OAE.get_embedding(query)\n",
    "    sims = list(np.argsort(cosine_similarity([equery], enews)[0]))\n",
    "    \n",
    "    news1 = [news[sims.index(0)], news[sims.index(1)], news[sims.index(2)]]\n",
    "    news1 = ['title: ' + i['headline'] + '\\n' + 'news summary: ' + str(i['abstract']) for i in news1]\n",
    "    news1 = '\\n'.join(news1)\n",
    "    \n",
    "    if len(news) < 6:\n",
    "        return news1, -1\n",
    "    \n",
    "    news2 = [news[sims.index(3)], news[sims.index(4)], news[sims.index(5)]]\n",
    "    news2 = ['title: ' + i['headline'] + '\\n' + 'news summary: ' + str(i['abstract']) for i in news2]\n",
    "    news2 = '\\n'.join(news2)\n",
    "    return 'recent news: \\n' + news1, 'recent news: \\n' + news2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e9f2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2015-01-01'\n",
    "end_date = '2024-01-01'\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "formatted_dates = date_range.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "# formatted_dates, company100_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c0bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_included = 3\n",
    "financials_included = 10\n",
    "volume_included = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55012323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBL\n",
      "precheck: company does not have financials BBL\n",
      "SPG\n",
      "precheck: company does not have financials SPG\n",
      "C\n",
      "precheck: company does not have financials C\n",
      "PTR\n",
      "precheck: company does not have financials PTR\n",
      "RDS-B\n",
      "precheck: company does not have financials RDS-B\n"
     ]
    }
   ],
   "source": [
    "for ticker in ['BBL', 'SPG', 'C', 'PTR', 'RDS-B']:\n",
    "    print(ticker)\n",
    "    prompts = []\n",
    "    targets = []\n",
    "    targets_bin = []\n",
    "    dates = []\n",
    "    companies = []\n",
    "    \n",
    "    try:\n",
    "        financials = pd.read_csv(financials_data_path+ticker+dotcsv)\n",
    "        if not len(financials)>10:\n",
    "            print('precheck: company does not have financials', ticker)\n",
    "            continue\n",
    "    except:\n",
    "        print('precheck: company does not have financials', ticker)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        historics = pd.read_csv(historic_data_path+ticker+dotcsv)\n",
    "        if not len(historics)>10:\n",
    "            print('precheck: company does not have historics', ticker)\n",
    "            continue\n",
    "    except:\n",
    "        print('precheck: company does not have historics', ticker)\n",
    "        continue\n",
    "    \n",
    "    for qdate in tqdm(formatted_dates[1:]):\n",
    "        \n",
    "        target_bin = get_target(ticker, qdate, binn = True)\n",
    "        target = get_target(ticker, qdate, binn = False)\n",
    "        if target_bin == -1 or target == -1:\n",
    "            print(qdate, ticker, 'no target unavailable.')\n",
    "            continue\n",
    "            \n",
    "        historic = process_historic(ticker, qdate, volume_included) # for 0.4 chance include volume\n",
    "        financials = process_financials(ticker, qdate, include = random.randint(13, 15)) # 10 features included\n",
    "        \n",
    "        if historic != -1 and financials != -1:\n",
    "            fin = list([historic, financials])\n",
    "        elif historic == -1 and financials != -1:\n",
    "            fin = [financials]\n",
    "        elif historic != -1 and financials == -1:\n",
    "            fin = [historic]\n",
    "        else:\n",
    "            print(qdate, ticker, 'main for: no financials.')\n",
    "            continue\n",
    "        \n",
    "        news1, news2 = process_news(ticker, qdate, include = news_included) # 3 news included\n",
    "        \n",
    "        if news1 == -1 and news2 == -1:\n",
    "            print(qdate, ticker, 'main for: no news data available.')\n",
    "            continue\n",
    "        elif news1 != -1 and news2 == -1:\n",
    "            prompt_list1 = fin + [news1]\n",
    "            prompt_list2 = -1\n",
    "        elif news1 != -1 and news2 != -1:\n",
    "            news12 = [news1, news2]\n",
    "            random.shuffle(news12)\n",
    "            [news1, news2] = news12\n",
    "            prompt_list1 = fin + [news1]\n",
    "            prompt_list2 = fin + [news2]\n",
    "        \n",
    "        random.shuffle(prompt_list1)\n",
    "        prompt1 = '\\n'.join(prompt_list1)\n",
    "        prompts.append(prompt1)\n",
    "        targets.append(target)\n",
    "        targets_bin.append(target_bin)\n",
    "        dates.append(qdate)\n",
    "        companies.append(ticker)\n",
    "        \n",
    "        if len(prompt_list1) == 3:\n",
    "            sample_prompt = random.sample(prompt_list1, 2)\n",
    "            random.shuffle(sample_prompt)\n",
    "            prompt3 = '\\n'.join(sample_prompt)\n",
    "            prompts.append(prompt3)\n",
    "            targets.append(target)\n",
    "            targets_bin.append(target_bin)\n",
    "            dates.append(qdate)\n",
    "            companies.append(ticker)\n",
    "        \n",
    "        if prompt_list2 != -1:\n",
    "            random.shuffle(prompt_list2)\n",
    "            prompt2 = '\\n'.join(prompt_list2)\n",
    "            prompts.append(prompt2)\n",
    "            targets.append(target)\n",
    "            targets_bin.append(target_bin)\n",
    "            dates.append(qdate)\n",
    "            companies.append(ticker)\n",
    "            \n",
    "            if len(prompt_list2) == 3:\n",
    "                sample_prompt = random.sample(prompt_list2, 2)\n",
    "                random.shuffle(sample_prompt)\n",
    "                prompt4 = '\\n'.join(sample_prompt)\n",
    "                prompts.append(prompt4)\n",
    "                targets.append(target)\n",
    "                targets_bin.append(target_bin)\n",
    "                dates.append(qdate)\n",
    "                companies.append(ticker)\n",
    "                \n",
    "    print('-'*3, len(companies), 'data created for', ticker)\n",
    "        \n",
    "    prompts_dict = {'prompts': prompts, 'targets': targets, \n",
    "                'targets_bin': targets_bin, 'dates': dates, 'companies':companies}\n",
    " \n",
    "    with open('./prompts/' + ticker + '.pkl', 'wb') as file:  \n",
    "        pickle.dump(prompts_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b29de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSA.pkl\n",
      "PLD.pkl\n",
      "SNPMF.pkl\n",
      "WELL.pkl\n",
      "DD.pkl\n",
      "CMCSA.pkl\n",
      "LOW.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34276"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf= []\n",
    "for i in os.listdir('./prompts'):\n",
    "    if not i == '.DS_Store':\n",
    "        file = open(\"./prompts/\"+i,'rb')\n",
    "        object_file = pickle.load(file)\n",
    "        if len(object_file['targets']) <= 200:\n",
    "            print(i)\n",
    "        asdf.append(len(object_file['targets']))\n",
    "sum(asdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a0aef7",
   "metadata": {},
   "source": [
    "### Create Sentiment Analysis Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2ec09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python",
   "language": "python",
   "name": "env_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
